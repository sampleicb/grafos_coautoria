{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43241c24-4a5c-443b-9110-25f9562c95c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDE80 LOTE: batch_size=100, batch_number=0\n['pubmed25n1264.xml.gz']\n✅ Archivos del lote: 1 (0–99)\n\uD83D\uDCDA Archivos cargados en RDD: 1\n✅ Muestra lote #0\n+--------+-------------------------------------------------------------------------------------------+--------+--------------------+------+---------+--------+-------------+---------------------+---+-----------------------------+---+---+--------------+-----+--------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------+-----+\n|pmid    |title                                                                                      |pub_year|journal             |volume|issn     |language|country      |citation             |mid|doi                          |pii|pmc|fore          |last |fullname            |orcid|affiliation                                                                                                                            |affiliation_country|term             |major|\n+--------+-------------------------------------------------------------------------------------------+--------+--------------------+------+---------+--------+-------------+---------------------+---+-----------------------------+---+---+--------------+-----+--------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------+-----+\n|39460502|Associations Between Obesity and Risk of Thyroid Cancer: A Meta-Analysis of Cohort Studies.|2025    |Nutrition and cancer|77    |1532-7914|eng     |United States|Nutr Cancer, 77, 2025|   |10.1080/01635581.2024.2419488|   |   |Urfa Khairatun|Hisan|Urfa Khairatun Hisan|     |Department of Cancer Control and Population Health, National Cancer Center Graduate School of Cancer Science and Policy, Goyang, Korea.|                   |Humans           |N    |\n|39460502|Associations Between Obesity and Risk of Thyroid Cancer: A Meta-Analysis of Cohort Studies.|2025    |Nutrition and cancer|77    |1532-7914|eng     |United States|Nutr Cancer, 77, 2025|   |10.1080/01635581.2024.2419488|   |   |Urfa Khairatun|Hisan|Urfa Khairatun Hisan|     |Department of Cancer Control and Population Health, National Cancer Center Graduate School of Cancer Science and Policy, Goyang, Korea.|                   |Thyroid Neoplasms|Y    |\n|39460502|Associations Between Obesity and Risk of Thyroid Cancer: A Meta-Analysis of Cohort Studies.|2025    |Nutrition and cancer|77    |1532-7914|eng     |United States|Nutr Cancer, 77, 2025|   |10.1080/01635581.2024.2419488|   |   |Urfa Khairatun|Hisan|Urfa Khairatun Hisan|     |Department of Cancer Control and Population Health, National Cancer Center Graduate School of Cancer Science and Policy, Goyang, Korea.|                   |Obesity          |Y    |\n|39460502|Associations Between Obesity and Risk of Thyroid Cancer: A Meta-Analysis of Cohort Studies.|2025    |Nutrition and cancer|77    |1532-7914|eng     |United States|Nutr Cancer, 77, 2025|   |10.1080/01635581.2024.2419488|   |   |Urfa Khairatun|Hisan|Urfa Khairatun Hisan|     |Department of Cancer Control and Population Health, National Cancer Center Graduate School of Cancer Science and Policy, Goyang, Korea.|                   |Risk Factors     |N    |\n|39460502|Associations Between Obesity and Risk of Thyroid Cancer: A Meta-Analysis of Cohort Studies.|2025    |Nutrition and cancer|77    |1532-7914|eng     |United States|Nutr Cancer, 77, 2025|   |10.1080/01635581.2024.2419488|   |   |Urfa Khairatun|Hisan|Urfa Khairatun Hisan|     |Department of Cancer Control and Population Health, National Cancer Center Graduate School of Cancer Science and Policy, Goyang, Korea.|                   |Cohort Studies   |N    |\n+--------+-------------------------------------------------------------------------------------------+--------+--------------------+------+---------+--------+-------------+---------------------+---+-----------------------------+---+---+--------------+-----+--------------------+-----+---------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------+-----+\nonly showing top 5 rows\n✅ Lote #0 guardado en Delta: dbfs:/FileStore/pubmed_parquet/articulos_aux1\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# \uD83D\uDCCC 0) Widgets para controlar el lote\n",
    "# dbutils.notebook.run(\"parse_and_download_batch\", 0, {\"batch_size\": \"100\", \"batch_number\": \"0\"})\n",
    "# =============================================\n",
    "dbutils.widgets.text(\"batch_size\", \"100\")\n",
    "dbutils.widgets.text(\"batch_number\", \"\") # son 12  total\n",
    "\n",
    "batch_size = int(dbutils.widgets.get(\"batch_size\"))\n",
    "batch_number = int(dbutils.widgets.get(\"batch_number\"))\n",
    "\n",
    "print(f\"\uD83D\uDE80 LOTE: batch_size={batch_size}, batch_number={batch_number}\")\n",
    "\n",
    "# =============================================\n",
    "# 1) Construir lista de archivos SOLO para este lote\n",
    "# =============================================\n",
    "#pubmed25n1263\n",
    "#pubmed25n1258.xml.gz\n",
    "all_files = [f.name for f in dbutils.fs.ls(\"dbfs:/FileStore/pubmed_filtrado/\") if f.name.endswith(\".xml.gz\") ]\n",
    "\n",
    "#print(all_files)\n",
    "# Ordenar para consistencia\n",
    "all_files = sorted(all_files)\n",
    "\n",
    "start = batch_number * batch_size\n",
    "end = start + batch_size\n",
    "batch_files = all_files[start:end]\n",
    "\n",
    "print(f\"✅ Archivos del lote: {len(batch_files)} ({start}–{end-1})\")\n",
    "\n",
    "if not batch_files:\n",
    "    raise Exception(f\"\uD83D\uDEAB No hay archivos en este rango: {start}–{end}\")\n",
    "\n",
    "# =============================================\n",
    "# 2) Crear RDD solo con archivos del lote\n",
    "# =============================================\n",
    "rdd = sc.binaryFiles(\",\".join([f\"dbfs:/FileStore/pubmed_filtrado/{f}\" for f in batch_files]))\n",
    "#rdd = sc.binaryFiles(\",\".join([f\"dbfs:/FileStore/pubmed_filtrado/{f}\" for f in all_files]))\n",
    "print(f\"\uD83D\uDCDA Archivos cargados en RDD: {rdd.count()}\")\n",
    "\n",
    "# =============================================\n",
    "# 3) Tu función optimizada: igual\n",
    "# =============================================\n",
    "import xml.etree.ElementTree as ET\n",
    "import gzip\n",
    "import io\n",
    "\n",
    "\n",
    "def extract_country_from_affiliation(affiliation):\n",
    "    countries = [\n",
    "    \"Afghanistan\", \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"Antigua and Barbuda\",\n",
    "    \"Argentina\", \"Armenia\", \"Australia\", \"Austria\", \"Azerbaijan\",\n",
    "    \"Bahamas\", \"Bahrain\", \"Bangladesh\", \"Barbados\", \"Belarus\", \"Belgium\",\n",
    "    \"Belize\", \"Benin\", \"Bhutan\", \"Bolivia\", \"Bosnia and Herzegovina\", \"Botswana\",\n",
    "    \"Brazil\", \"Brunei\", \"Bulgaria\", \"Burkina Faso\", \"Burundi\",\n",
    "    \"Cambodia\", \"Cameroon\", \"Canada\", \"Cape Verde\", \"Central African Republic\",\n",
    "    \"Chad\", \"Chile\", \"China\", \"Colombia\", \"Comoros\", \"Congo\", \"Costa Rica\",\n",
    "    \"Croatia\", \"Cuba\", \"Cyprus\", \"Czech Republic\", \"Denmark\", \"Djibouti\",\n",
    "    \"Dominica\", \"Dominican Republic\", \"Ecuador\", \"Egypt\", \"El Salvador\",\n",
    "    \"Equatorial Guinea\", \"Eritrea\", \"Estonia\", \"Eswatini\", \"Ethiopia\",\n",
    "    \"Fiji\", \"Finland\", \"France\", \"Gabon\", \"Gambia\", \"Georgia\", \"Germany\",\n",
    "    \"Ghana\", \"Greece\", \"Grenada\", \"Guatemala\", \"Guinea\", \"Guinea-Bissau\",\n",
    "    \"Guyana\", \"Haiti\", \"Honduras\", \"Hungary\", \"Iceland\", \"India\", \"Indonesia\",\n",
    "    \"Iran\", \"Iraq\", \"Ireland\", \"Israel\", \"Italy\", \"Jamaica\", \"Japan\",\n",
    "    \"Jordan\", \"Kazakhstan\", \"Kenya\", \"Kiribati\", \"Kuwait\", \"Kyrgyzstan\",\n",
    "    \"Laos\", \"Latvia\", \"Lebanon\", \"Lesotho\", \"Liberia\", \"Libya\", \"Liechtenstein\",\n",
    "    \"Lithuania\", \"Luxembourg\", \"Madagascar\", \"Malawi\", \"Malaysia\", \"Maldives\",\n",
    "    \"Mali\", \"Malta\", \"Marshall Islands\", \"Mauritania\", \"Mauritius\", \"Mexico\",\n",
    "    \"Micronesia\", \"Moldova\", \"Monaco\", \"Mongolia\", \"Montenegro\", \"Morocco\",\n",
    "    \"Mozambique\", \"Myanmar\", \"Namibia\", \"Nauru\", \"Nepal\", \"Netherlands\",\n",
    "    \"New Zealand\", \"Nicaragua\", \"Niger\", \"Nigeria\", \"North Korea\", \"North Macedonia\",\n",
    "    \"Norway\", \"Oman\", \"Pakistan\", \"Palau\", \"Panama\", \"Papua New Guinea\",\n",
    "    \"Paraguay\", \"Peru\", \"Philippines\", \"Poland\", \"Portugal\", \"Qatar\",\n",
    "    \"Romania\", \"Russia\", \"Rwanda\", \"Saint Kitts and Nevis\", \"Saint Lucia\",\n",
    "    \"Saint Vincent and the Grenadines\", \"Samoa\", \"San Marino\", \"Sao Tome and Principe\",\n",
    "    \"Saudi Arabia\", \"Senegal\", \"Serbia\", \"Seychelles\", \"Sierra Leone\",\n",
    "    \"Singapore\", \"Slovakia\", \"Slovenia\", \"Solomon Islands\", \"Somalia\",\n",
    "    \"South Africa\", \"South Korea\", \"South Sudan\", \"Spain\", \"Sri Lanka\",\n",
    "    \"Sudan\", \"Suriname\", \"Sweden\", \"Switzerland\", \"Syria\", \"Taiwan\",\n",
    "    \"Tajikistan\", \"Tanzania\", \"Thailand\", \"Timor-Leste\", \"Togo\", \"Tonga\",\n",
    "    \"Trinidad and Tobago\", \"Tunisia\", \"Turkey\", \"Turkmenistan\", \"Tuvalu\",\n",
    "    \"Uganda\", \"Ukraine\", \"United Arab Emirates\", \"United Kingdom\",\n",
    "    \"United States\", \"Uruguay\", \"Uzbekistan\", \"Vanuatu\", \"Vatican City\",\n",
    "    \"Venezuela\", \"Vietnam\", \"Yemen\", \"Zambia\", \"Zimbabwe\"\n",
    "]\n",
    "    for country in countries:\n",
    "        if country.lower() in affiliation.lower():\n",
    "            return country\n",
    "    return \"\"\n",
    "\n",
    "def get_full_text(element):\n",
    "    text = element.text or \"\"\n",
    "    for child in element:\n",
    "        text += get_full_text(child)\n",
    "        text += child.tail or \"\"\n",
    "    return text.strip()\n",
    "\n",
    "def parse_gz_bytes1(pair):\n",
    "    filename, content = pair\n",
    "    registros = []\n",
    "\n",
    "    try:\n",
    "        with gzip.GzipFile(fileobj=io.BytesIO(content)) as f:\n",
    "           \n",
    "            context = ET.iterparse(f, events=(\"end\",))\n",
    "            for _, elem in context:\n",
    "                if elem.tag == \"PubmedArticle\":\n",
    "                    try:\n",
    "\n",
    "                        pub_date = elem.find(\"MedlineCitation/Article/Journal/JournalIssue/PubDate\")\n",
    "                        pub_year = pub_date.findtext(\"Year\") if pub_date is not None else \"\"\n",
    "                        if not pub_year and pub_date is not None:\n",
    "                            pub_year = pub_date.findtext(\"MedlineDate\") or \"\"\n",
    "                            #print(pub_year ) \n",
    "                        # ✅ Normaliza a solo 4 dígitos si viene como rango\n",
    "                        #pub_year_clean = pub_year[:4] if pub_year else \"\"\n",
    "                        #print(pub_year_clean )         \n",
    "                        # ⚠️ Si NO está entre 2020 y 2025 → saltar este artículo\n",
    "                        #if not pub_year_clean.isdigit() or not (2020 <= int(pub_year_clean) <= 2025):\n",
    "                        # elem.clear()\n",
    "                        # continue\n",
    "\n",
    "                        pmid = elem.findtext(\"MedlineCitation/PMID\") or \"\"\n",
    "                       \n",
    "                        title = elem.findtext(\"MedlineCitation/Article/ArticleTitle\") or \"\"\n",
    "                           \n",
    "                       \n",
    "                        journal = elem.findtext(\"MedlineCitation/Article/Journal/Title\") or \"\"\n",
    "                        issn = elem.findtext(\"MedlineCitation/Article/Journal/ISSN\") or \"\"\n",
    "                        volume = elem.findtext(\"MedlineCitation/Article/Journal/JournalIssue/Volume\") or \"\"\n",
    "                        language = elem.findtext(\"MedlineCitation/Article/Language\") or \"\"\n",
    "                        country = elem.findtext(\"MedlineCitation/MedlineJournalInfo/Country\") or \"\"\n",
    "                            \n",
    "                        \n",
    "\n",
    "                        doi = \"\"\n",
    "                        pii = \"\"\n",
    "                        pmc = \"\"\n",
    "                        for aid in elem.iter(\"ArticleId\"):\n",
    "                            id_type = aid.attrib.get(\"IdType\", \"\").lower()\n",
    "                            if id_type == \"doi\" and aid.text:\n",
    "                                doi = aid.text.strip()\n",
    "                            elif id_type == \"pii\" and aid.text:\n",
    "                                pii = aid.text.strip()\n",
    "                            elif id_type == \"pmc\" and aid.text:\n",
    "                                pmc = aid.text.strip()\n",
    "\n",
    "                        mid = next((aid.text for aid in elem.iter(\"ArticleId\") if aid.attrib.get(\"IdType\") == \"mid\"), \"\")\n",
    "\n",
    "                      \n",
    "                        pub_types = [pt.text for pt in elem.iter(\"PublicationType\") if pt.text]\n",
    "\n",
    "                        journal_abbr = elem.findtext(\"MedlineCitation/Article/Journal/ISOAbbreviation\") or \"\"\n",
    "                        #country = elem.findtext(\"MedlineCitation/Article/Journal/Country\") or \"\"\n",
    "                        citation = f\"{journal_abbr}, {volume}, {pub_year}\"\n",
    "\n",
    "\n",
    "                        \n",
    "                       \n",
    "                                           \n",
    "                        \n",
    "                        authors = []\n",
    "                        for author in elem.iter(\"Author\"):\n",
    "                            fore = author.findtext(\"ForeName\") or \"\"\n",
    "                            last = author.findtext(\"LastName\") or \"\"\n",
    "                            fullname = f\"{fore} {last}\".strip()\n",
    "\n",
    "                            orcid = \"\"\n",
    "                            id_elem = author.find(\"Identifier\")\n",
    "                            if id_elem is not None and id_elem.attrib.get(\"Source\") == \"ORCID\":\n",
    "                                orcid = id_elem.text or \"\"\n",
    "                            \n",
    "                            #mesh_terms = []\n",
    "                            #for mesh in elem.iter(\"MeshHeading\"):\n",
    "                            #    desc = mesh.find(\"DescriptorName\")\n",
    "                            #    term = desc.text if desc is not None else \"\"\n",
    "                            #    major = desc.attrib.get(\"MajorTopicYN\", \"N\") if desc is not None else \"N\"\n",
    "                            #    mesh_terms.append(f\"{term}::{'Major' if major == 'Y' else 'Minor'}\")\n",
    "        \n",
    "\n",
    "                            affiliation = \"\"\n",
    "                            for aff_info in author.findall(\"AffiliationInfo\"):\n",
    "                                aff_node = aff_info.find(\"Affiliation\")\n",
    "                                if aff_node is not None:\n",
    "                                    affiliation = get_full_text(aff_node)\n",
    "\n",
    "                                    if affiliation is not None:\n",
    "                                        affiliation_country = extract_country_from_affiliation(affiliation)\n",
    "\n",
    "\n",
    "\n",
    "                                    #affiliation = \"\"\n",
    "                                    #aff = author.find(\"AffiliationInfo/Affiliation\")\n",
    "                                    #if aff is not None:\n",
    "                                    #affiliation = aff.text or \"\"\n",
    "                                    #affiliation_country = extract_country_from_affiliation(affiliation)\n",
    "\n",
    "\n",
    "                                    mesh_terms = []\n",
    "                                    for mesh in elem.iter(\"MeshHeading\"):\n",
    "                                        desc = mesh.find(\"DescriptorName\")\n",
    "                                        term = desc.text if desc is not None else \"\"\n",
    "                                        major = desc.attrib.get(\"MajorTopicYN\", \"N\") if desc is not None else \"N\"\n",
    "                            \n",
    "                                        registros.append((\n",
    "                                          pmid, title, pub_year, journal, volume, issn, language, country,\n",
    "                                          citation, mid,  doi, pii, pmc,fore, last,fullname, orcid\n",
    "                                        , affiliation, affiliation_country, term , major\n",
    "                                        \n",
    "                                        ))\n",
    "                        \n",
    "                    except:\n",
    "                        pass\n",
    "                    elem.clear()\n",
    "    except:\n",
    "        pass\n",
    "    return registros\n",
    "\n",
    "\n",
    "\n",
    "def parse_gz_bytes2(pair):\n",
    "    filename, content = pair\n",
    "    registros = []\n",
    "\n",
    "    try:\n",
    "        with gzip.GzipFile(fileobj=io.BytesIO(content)) as f:\n",
    "            context = ET.iterparse(f, events=(\"end\",))\n",
    "            for _, elem in context:\n",
    "                if elem.tag == \"PubmedArticle\":\n",
    "                    try:\n",
    "                       \n",
    "                        pmid = elem.findtext(\"MedlineCitation/PMID\") or \"\"\n",
    "                        authors = []\n",
    "                        for author in elem.iter(\"Author\"):\n",
    "                            fore = author.findtext(\"ForeName\") or \"\"\n",
    "                            last = author.findtext(\"LastName\") or \"\"\n",
    "                            fullname = f\"{fore} {last}\".strip()\n",
    "                                  \n",
    "                                  \n",
    "                            orcid = \"\"\n",
    "                            id_elem = author.find(\"Identifier\")\n",
    "                            if id_elem is not None and id_elem.attrib.get(\"Source\") == \"ORCID\":\n",
    "                                orcid = id_elem.text or \"\"\n",
    "\n",
    "                            affiliation = \"\"\n",
    "                            for aff_info in author.findall(\"AffiliationInfo\"):\n",
    "                                aff_node = aff_info.find(\"Affiliation\")\n",
    "                                if aff_node is not None:\n",
    "                                    affiliation = get_full_text(aff_node)\n",
    "                                    country_node = aff_info.find(\"Country\")\n",
    "                                    if country_node is not None:\n",
    "                                        affiliation_country = country_node.text\n",
    "                                    else:\n",
    "                                        affiliation_country = None\n",
    "                                 \n",
    "\n",
    "                                    # Una fila = artículo + autor + afiliación\n",
    "                                    registros.append((\n",
    "                                        fullname, orcid, affiliation, affiliation_country, pmid\n",
    "                                        \n",
    "                                    ))\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "                    elem.clear()\n",
    "    except:\n",
    "        pass\n",
    "    return registros\n",
    "# =============================================\n",
    "# 4) Ejecutar transformación en paralelo\n",
    "# =============================================\n",
    "parsed_rdd1 = rdd.flatMap(parse_gz_bytes1)\n",
    "#parsed_rdd2 = rdd.flatMap(parse_gz_bytes2)\n",
    "# =============================================\n",
    "# 5) Definir esquema igual\n",
    "# =============================================\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "\n",
    "pmid_file_struct = StructType([\n",
    "    StructField(\"pmid\", StringType(), True),\n",
    "    StructField(\"filename\", StringType(), True)\n",
    "   \n",
    "])\n",
    "\n",
    "author_struct = StructType([\n",
    "    StructField(\"fullname\", StringType(), True),\n",
    "    StructField(\"orcid\", StringType(), True),\n",
    "    StructField(\"affiliation\", StringType(), True),\n",
    "    StructField(\"affiliation_country\", StringType(), True),\n",
    "    StructField(\"pmid\", StringType(), True),\n",
    "   \n",
    "])\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"pmid\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"pub_year\", StringType(), True),\n",
    "    StructField(\"journal\", StringType(), True),\n",
    "    StructField(\"volume\", StringType(), True),\n",
    "    StructField(\"issn\", StringType(), True),\n",
    "    StructField(\"language\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"citation\", StringType(), True),\n",
    "    StructField(\"mid\", StringType(), True),\n",
    "    StructField(\"doi\", StringType(), True),\n",
    "    StructField(\"pii\", StringType(), True),\n",
    "    StructField(\"pmc\", StringType(), True),\n",
    "    StructField(\"fore\", StringType(), True),\n",
    "    StructField(\"last\", StringType(), True),\n",
    "    StructField(\"fullname\", StringType(), True),\n",
    "    StructField(\"orcid\", StringType(), True),\n",
    "    StructField(\"affiliation\", StringType(), True),\n",
    "    StructField(\"affiliation_country\", StringType(), True),\n",
    "    StructField(\"term\", StringType(), True),\n",
    "    StructField(\"major\", StringType(), True)\n",
    "   \n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    " \n",
    "# =============================================\n",
    "# 6) Crear DataFrame y guardar en append\n",
    "# =============================================\n",
    "df1 = spark.createDataFrame(parsed_rdd1, schema=schema)\n",
    "#df2 = spark.createDataFrame(parsed_rdd2, schema=author_struct)\n",
    "\n",
    "print(f\"✅ Muestra lote #{batch_number}\")\n",
    "df1.show(5, truncate=False)\n",
    "\n",
    "output_path = \"/FileStore/pubmed_parsed_batches\"\n",
    "output_path1 = \"dbfs:/FileStore/pubmed_parquet/articulos_aux\"\n",
    "#output_path2 = \"dbfs:/FileStore/pubmed_parquet/authors_aux\"\n",
    "\n",
    "#.partitionBy(\"year\", \"country\").\n",
    "\n",
    "df1.write.format(\"parquet\").mode(\"append\").save(output_path1)\n",
    "#df2.write.format(\"parquet\").mode(\"append\").save(output_path2)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"✅ Lote #{batch_number} guardado en Delta: {output_path1}\")\n",
    "#print(f\"✅ Lote #{batch_number} guardado en Delta: {output_path2}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4680148770149062,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_03_Parseo_Nuevo",
   "widgets": {
    "batch_number": {
     "currentValue": "0",
     "nuid": "f63085d4-550a-4f48-a85e-a70abf25601b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "1",
      "label": null,
      "name": "batch_number",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "1",
      "label": null,
      "name": "batch_number",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "batch_size": {
     "currentValue": "100",
     "nuid": "956badd1-3a84-4475-b0ee-6ce50d9fce88",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "100",
      "label": null,
      "name": "batch_size",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "100",
      "label": null,
      "name": "batch_size",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}