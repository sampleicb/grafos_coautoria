{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd45cb8d-2b2f-4842-a990-3cd8a8e0ccf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(\"USE CATALOG spark_catalog\")\n",
    "spark.sql(\"USE DATABASE default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f71e307f-6c4a-445d-9920-ffe4dbe51ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: pubmed_affiliaciones\nROR: unirdat.pubmed_db.n_affiliaciones\nOutput: unirdat.pubmed_db.m_autor_afiliacion_ror_normalized_final_3\nChunk size: 50\nTotal autores únicos: 1\n\n=== Procesando autores 0 → 0: ['agostino pierro'] ===\n✅ Chunk 0 → 0 guardado OK\n\n\uD83C\uDF89 TODOS LOS CHUNKS TERMINADOS \uD83D\uDE80\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# ✅ 1️⃣ Mejora final 2\n",
    "# ---------------------------------------------------------\n",
    "# ---------------------------------------------------------\n",
    "# ✅ 1️⃣ Widgets y variables\n",
    "# ---------------------------------------------------------\n",
    "dbutils.widgets.text(\"source_table\", \"pubmed_affiliaciones\", \"Tabla RAW\")\n",
    "dbutils.widgets.text(\"ror_table\", \"unirdat.pubmed_db.n_affiliaciones\", \"Tabla ROR Delta\")\n",
    "dbutils.widgets.text(\"output_table\", \"unirdat.pubmed_db.m_autor_afiliacion_ror_normalized_final_2\", \"Tabla final\")\n",
    "dbutils.widgets.text(\"chunk_size\", \"50\", \"Autores por chunk\")\n",
    "\n",
    "source_table = dbutils.widgets.get(\"source_table\")\n",
    "ror_table = dbutils.widgets.get(\"ror_table\")\n",
    "output_table = dbutils.widgets.get(\"output_table\")\n",
    "chunk_size = int(dbutils.widgets.get(\"chunk_size\"))\n",
    "\n",
    "print(f\"Source: {source_table}\")\n",
    "print(f\"ROR: {ror_table}\")\n",
    "print(f\"Output: {output_table}\")\n",
    "print(f\"Chunk size: {chunk_size}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ✅ 2️⃣ Librerías\n",
    "# ---------------------------------------------------------\n",
    "from pyspark.sql.functions import col, lower, trim, regexp_replace, monotonically_increasing_id, udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, NGram, HashingTF, MinHashLSH\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ✅ 3️⃣ UDF para filtrar vectores no vacíos\n",
    "# ---------------------------------------------------------\n",
    "def vector_nonzero(v):\n",
    "    if v is None:\n",
    "        return False\n",
    "    try:\n",
    "        return v.numNonzeros() > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "nonzero_udf = udf(vector_nonzero, BooleanType())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ✅ 4️⃣ Cargar tablas base y limpiar ROR\n",
    "# ---------------------------------------------------------\n",
    "df_all = spark.table(source_table).filter(col(\"nombre_completo\")==\"agostino pierro\")\n",
    "df_ror = spark.table(ror_table)\n",
    "\n",
    "df_ror_clean = df_ror.withColumn(\n",
    "    \"alias_clean\",\n",
    "    trim(regexp_replace(lower(col(\"aliases\")), \"[^a-zA-Z0-9 ]\", \"\"))\n",
    ").filter(\n",
    "    (col(\"alias_clean\").isNotNull()) & (col(\"alias_clean\") != \"\")\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ✅ 5️⃣ Obtener autores únicos\n",
    "# ---------------------------------------------------------\n",
    "autores = [row[\"nombre_completo\"] for row in df_all.select(\"nombre_completo\").distinct().collect()]\n",
    "print(f\"Total autores únicos: {len(autores)}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ✅ 6️⃣ Procesar por chunk de autores\n",
    "# ---------------------------------------------------------\n",
    "for i in range(0, len(autores), chunk_size):\n",
    "    batch = autores[i:i+chunk_size]\n",
    "    print(f\"\\n=== Procesando autores {i} → {i+len(batch)-1}: {batch} ===\")\n",
    "\n",
    "    # \uD83D\uDD39 6.1 Filtrar chunk\n",
    "    df_affil_ini = df_all.filter(col(\"nombre_completo\").isin(batch)) \\\n",
    "                         .select(\"nombre_completo\", \"affiliation\").distinct()\n",
    "\n",
    "    # \uD83D\uDD39 6.2 Limpiar texto\n",
    "    df_affil_clean = df_affil_ini.withColumn(\n",
    "        \"affiliation_clean\",\n",
    "        trim(regexp_replace(lower(col(\"affiliation\")), \"[^a-zA-Z0-9 ]\", \"\"))\n",
    "    ).filter(\n",
    "        (col(\"affiliation_clean\").isNotNull()) & (col(\"affiliation_clean\") != \"\")\n",
    "    )\n",
    "\n",
    "    df_affil_clean = df_affil_clean.withColumn(\"id_aff\", monotonically_increasing_id())\n",
    "\n",
    "    # \uD83D\uDD39 6.3 Exact match\n",
    "    df_exact = df_affil_clean.join(\n",
    "        df_ror_clean,\n",
    "        df_affil_clean.affiliation_clean == df_ror_clean.alias_clean,\n",
    "        \"left\"\n",
    "    ).withColumn(\n",
    "        \"affiliation_normalized\",\n",
    "        col(\"name\")\n",
    "    ).withColumn(\n",
    "        \"ror_id\",\n",
    "        col(\"id\")\n",
    "    )\n",
    "\n",
    "    df_exact_ok = df_exact.filter(col(\"ror_id\").isNotNull()) \\\n",
    "        .select(\"nombre_completo\", \"id_aff\", \"affiliation\", \"ror_id\", \"affiliation_normalized\")\n",
    "\n",
    "    df_no_match = df_exact.filter(col(\"ror_id\").isNull()) \\\n",
    "        .select(\"id_aff\", \"nombre_completo\", \"affiliation\", \"affiliation_clean\") \\\n",
    "        .persist()\n",
    "\n",
    "    # \uD83D\uDD39 6.4 Fuzzy match solo si hay sin match\n",
    "    if df_no_match.count() > 0:\n",
    "        tokenizer = Tokenizer(inputCol=\"affiliation_clean\", outputCol=\"words\")\n",
    "        df_affil_tokens = tokenizer.transform(df_no_match)\n",
    "\n",
    "        tokenizer_ror = Tokenizer(inputCol=\"alias_clean\", outputCol=\"words\")\n",
    "        df_ror_tokens = tokenizer_ror.transform(df_ror_clean)\n",
    "\n",
    "        hashingTF = HashingTF(inputCol=\"words\", outputCol=\"features\", numFeatures=2000)\n",
    "        df_affil_features = hashingTF.transform(df_affil_tokens)\n",
    "        df_ror_features = hashingTF.transform(df_ror_tokens)\n",
    "\n",
    "        # ✅ Filtrar vectores vacíos en ambos lados\n",
    "        df_affil_features_filtered = df_affil_features.filter(is_nonzero_udf(\"features\"))\n",
    "        df_ror_features_filtered = df_ror_features.filter(is_nonzero_udf(\"features\"))\n",
    "\n",
    "        lsh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=10)\n",
    "        lsh_model = lsh.fit(df_ror_features_filtered)\n",
    "\n",
    "        df_matches = lsh_model.approxSimilarityJoin(\n",
    "            df_affil_features_filtered,\n",
    "            df_ror_features_filtered,\n",
    "            0.8,\n",
    "            distCol=\"JaccardDistance\"\n",
    "        ).select(\n",
    "            col(\"datasetA.id_aff\"),\n",
    "            col(\"datasetA.nombre_completo\"),\n",
    "            col(\"datasetA.affiliation\"),\n",
    "            col(\"datasetB.id\").alias(\"ror_id_fuzzy\"),\n",
    "            col(\"datasetB.name\").alias(\"name_fuzzy\"),\n",
    "            col(\"JaccardDistance\")\n",
    "        )\n",
    "\n",
    "        w = Window.partitionBy(\"id_aff\").orderBy(col(\"JaccardDistance\").asc())\n",
    "        df_best_matches = df_matches.withColumn(\n",
    "            \"rn\",\n",
    "            row_number().over(w)\n",
    "        ).filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "\n",
    "        df_fuzzy_ok = df_best_matches.withColumnRenamed(\"ror_id_fuzzy\", \"ror_id\") \\\n",
    "            .withColumnRenamed(\"name_fuzzy\", \"affiliation_normalized\") \\\n",
    "            .select(\"nombre_completo\", \"id_aff\", \"affiliation\", \"ror_id\", \"affiliation_normalized\")\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Dataframe vacío compatible si no hay sin match\n",
    "        df_fuzzy_ok = spark.createDataFrame([], df_exact_ok.schema)\n",
    "\n",
    "    # \uD83D\uDD39 6.5 Combinar exact + fuzzy\n",
    "    df_final = df_exact_ok.unionByName(df_fuzzy_ok)\n",
    "\n",
    "    # \uD83D\uDD39 6.6 Guardar chunk incremental con mergeSchema\n",
    "    df_final.write.mode(\"append\").format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .saveAsTable(output_table)\n",
    "\n",
    "    print(f\"✅ Chunk {i} → {i+len(batch)-1} guardado OK\")\n",
    "\n",
    "print(\"\\n\uD83C\uDF89 TODOS LOS CHUNKS TERMINADOS \uD83D\uDE80\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5723474551589695,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_EDA_Nuevo_04_Normalizacion_table_affiliaciones_test_norm2",
   "widgets": {
    "chunk_size": {
     "currentValue": "50",
     "nuid": "bd047e15-5e50-451b-834d-bfb3a6a90b9f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "50",
      "label": "Autores por chunk",
      "name": "chunk_size",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "50",
      "label": "Autores por chunk",
      "name": "chunk_size",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "output_table": {
     "currentValue": "unirdat.pubmed_db.m_autor_afiliacion_ror_normalized_final_2",
     "nuid": "38de0a67-ab53-4808-bd6b-bc4facdf6179",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "unirdat.pubmed_db.m_autor_afiliacion_ror_normalized_final_2",
      "label": "Tabla final",
      "name": "output_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "unirdat.pubmed_db.m_autor_afiliacion_ror_normalized_final_2",
      "label": "Tabla final",
      "name": "output_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "ror_table": {
     "currentValue": "unirdat.pubmed_db.n_affiliaciones",
     "nuid": "189b7df7-294e-45f8-913e-3c7a2a3c4e55",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "unirdat.pubmed_db.n_affiliaciones",
      "label": "Tabla ROR Delta",
      "name": "ror_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "unirdat.pubmed_db.n_affiliaciones",
      "label": "Tabla ROR Delta",
      "name": "ror_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "source_table": {
     "currentValue": "pubmed_affiliaciones",
     "nuid": "2589ec18-9d25-4351-8c05-5c31a5cf8ed3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "pubmed_affiliaciones",
      "label": "Tabla RAW",
      "name": "source_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "pubmed_affiliaciones",
      "label": "Tabla RAW",
      "name": "source_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "tmp_path": {
     "currentValue": "/mnt/tmp/pubmed_affil_norm",
     "nuid": "92be96ca-cc23-47c7-afd8-bc6c9583354d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/mnt/tmp/pubmed_affil_norm",
      "label": "Ruta temporal Delta",
      "name": "tmp_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/mnt/tmp/pubmed_affil_norm",
      "label": "Ruta temporal Delta",
      "name": "tmp_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}